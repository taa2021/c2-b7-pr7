# C2.B6 Проектная работа 6. Управление конфигурациями (Ansible, Puppet)


## Задание

Оригинальная формулировка задания приведена [здесь](./TASK.md).

## Примечания к решению

- "Аппаратные" характеристики развертываемых хостов уменьшены по сравнению с требуемыми согласно заданию -
в соответствии с требованиями Куратора курса об использовании минимально возможных ресурсов.

- После развертывания решения задания и сбора доказательств успешности развертывания ресурсы в Я.Облаке были удалены - 
в соответствии с требованиями Куратора курса об использовании минимально возможных ресурсов,
в соответствии с неоднократными заявлениями Ментора об отсутствии необходимости "держать включенными ресурсы"
только для проверки задания, а также о достаточности предоставления в качестве решения ссылки на репозиторий 
(и дополнительных подтверждающих материалов).

- При решении/развертывании токены сеанса Я.Облака, ключей сервис-аккаунта Я.Облачного бекенд-хранилища
Terraform задавались через переменные среды окружения, ssh-ключ - "пробрасывался" через "бастион"
на оконечные хосты (agent forwarding), т.к. хранение закрытого ключа (даже в контейнере с паролем: 
похищение и подбор пароля к закрытому ключу оффлайн - возможны, вероятны, актуальны) на транзитном
хосте еще и совмещенными ролями "бастион", "web", "database" - прямое игнорирование требований ИБ.
Настройки конфигурационных файлов, позволющих осуществлять прокси-подключение по ssh до хостов в закрытой сети
без прямого доступа в интернет - приведены в репозитории: 
[ansible.ini](./live/dev/app/ansible.ini), 
[конфигурационный файл](./live/dev/app/conf/ssh-via-bastion.config) клиента ssh (шаблонизирован из 
[файла](./live/dev/app/templates/ssh-via-bastion.config.tfpl))

- Создание пользователя с определенным ssh-ключом на виртуальных машинах произведено с помощью terraform
с помощью яндекс-провайдера при создании виртуальных машин.

- Подразумевается, что для инфраструктуры жизненного цикла development, stage, production - бэкенды хранения состояний
terraform - разные, учетные записи облачных инфраструктур - разные (и пока реализована только dev).

- В качестве варианта, позволяющего организовать доступ хостов в закрытой сети к информации в репозиториях ПО
и к пакетам ПО, принято решение использования прокси-сервера на бастионе (настройка - минимальна: ограничение 
на уровне МЭ узла бастиона доступа к прокси - только для хостов закрытой подсети).

- Развертывание производится сначала с помощью terraform и после отработки непосредственно создания инфраструктуры -
в terraform-е локальным вызовом ansible для удаленной настройки развернутых серверов. 
[Inventory](./live/dev/app/conf/inventory) - заполняется автоматически.
Inventory (см. [шаблон](./live/dev/app/templates/inventory.tftpl)), часть файлов - шаблонизированы в т.ч. на уровне развертывания непосредстенно terraform (например, "запоминание" 
внутреннего и внешнего адреса "бастиона"), что необходимо учесть при правке необходимых значений констант-"переменных" (например, 
версии каталога данных сервиса posgresql)
и править - в шаблоне.

- Чтобы ansible отрабатывал на хостах в закрытой сети без непосредственного доступа в интернет,
 чтобы устанавливались необходимые пакеты на указанных хостах,- проведена определенная процедура раскрутки готовности.

- "Установка и запуск Docker" (цитата из формулировке задания) - в чистом виде оксюморон:
или мы должны установить ПО "генерации образов" и запустить его, 
или установить некую неважно какую службу управления контейнерами,
причем в задании полностью отсутствует требование по эквивалентности решения для запуска docker-а
между узлами инфраструктуры (группа app), и можно, аналогично заданию из 
модуля С2.B1. "Современные методологии разработки" сделать - согласно принципу выполнения
минимально допустимой и достаточной работы и недопущения ранней автоматизации -
где-то установить containerd, где-то - только runc, а где-то - только утилиты командной
строки для создания образа.  Причем данное решение было бы в рамках концепции школы -
"В этом плане все эти требования гибки." (c) Ментор ("план" - см. [здесь](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D0%BD%D1%82%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D0%BB%D0%B0%D0%BD)).
Тем не менее, принято решение установки на хостах, в т.ч. с разными ОС, набора утилит, сервисов
из одного источника (https://docs.docker.com/engine/install/).

- Согласно требованию задания playbook-и необходимо было написать (не списать с ansible-galaxy),
что и было реализовано в предлагаемом решении.

- Для развертывания postgresql написанный playbook поддерживает в качестве семейства ОС на хосте как "ubuntu", так и "centos".

- Тестирование проводилось в том числе неоднократным полным развертыванием.

- При обучении примеров совместного использования решений terraform и ansible с требованием 
к оформлению структуры каталогов - не приводилось; разнесение в рамках решения данной учебной задачи
признано несущественным.

## Ход решения (принципиальная схема развертывания)

0. [Запрашиваем токен для Я.Облака](https://cloud.yandex.ru/docs/iam/operations/iam-token/create),
результат экспортируем в переменной окружения

```
export TF_VAR_yc_iam_token=`yc iam create-token`
```

1. Создаем бекенд-хранилище для terraform данного проекта данной стадии жизненного цикла (dev)

```
cd (__GIT_PROJECT_ROOT__)/global/tf-state-storage
# правим значения параметров в variables.tf
#...
# инициализируем среду Terraform
terraform init
# просматриваем план развертывания
terraform plan
# если всё устраивает - развертываем
terraform apply
```

На доверенном терминале просматриваем в том числе секрето-чувствительные параметры,
ключи аутентификации для s3-хранилища бэкенда - экспортируем в переменных среды окружения.

```
terraform output -json
export AWS_ACCESS_KEY_ID='...'
export AWS_SECRET_ACCESS_KEY='...'

```

2. Для развертываемого стенда проекта данной стадии жизненного цикла (dev) правим параметры развертывания
(variables.tf), параметры бекенда Terraform (при необходимости), проводим развертывание
```
cd (__GIT_PROJECT_ROOT__)/live/dev/app
# правим значения параметров в variables.tf
#...
# правим значения параметров S3-бекенда терраформ (main.tf)
#...
# инициализируем среду Terraform
terraform init
# просматриваем план развертывания
terraform plan
# если всё устраивает - осуществляем процедуру развертывания
terraform apply
```

3. Итоги развертывания:
- ход развертывания - [здесь](https://disk.yandex.ru/d/iisDMDYIzThcrA).
- инвентарь (после рендера шаблонизатором) - [здесь](https://disk.yandex.ru/d/xFp7B-6dckOF7Q).
- скриншоты запущенных служб: 
    - [vm1](https://disk.yandex.ru/i/YzYjra_pnGHLew)
    - [vm2](https://disk.yandex.ru/i/0VFfPeQB3uXeSA)
    - [vm3](https://disk.yandex.ru/i/hK1plC2soksVnw)
- плейбуки:
    - [промежуточный, шаблон](./live/dev/app//templates/bootstrap-bastion-0.yml.tfpl). Решение задачи "Установить на vm1 Ansible." - подготовка (ansible должен отрабатывать сколь возможно предсказуемо, поэтому python - требуем 3ей версии).
    - [промежуточный, шаблон](./live/dev/app//templates/bootstrap-bastion-1.yml.tfpl). Решение задачи "Установить на vm1 Ansible." - непосредственно, а также подготовка к развертыванию ролей.
    - [промежуточный, шаблон](./live/dev/app//templates/bootstrap-bastion-2.yml.tfpl). Решение задачи " выполняется установка и запуск" - подготовка (ansible должен отрабатывать сколь возможно предсказуемо, поэтому python - требуем 3ей версии).
    - [промежуточный, шаблон](./live/dev/app//templates/bootstrap-bastion-3.yml.tfpl). Решение задачи " выполняется установка и запуск" - непосредственно развертывание ролей.
- Отдельно вывод по результату развертывания:

```
Outputs:

ansible-inventory = "./conf/inventory"
ehost = "51.250.5.193"
hosts = <<EOT
192.168.1.7
192.168.1.5
192.168.1.9
EOT

```

## Выводы по решению 

- Два хоста с ОС нужных версий - развернуты, из Internet хосты - доступен только "бастион",
 Internet напрямую - доступен только с хоста "бастион".
- Требуемые службы на заданных согласно заданию хостах с помощью playbook ansible-а - развернуты, запущены, работают.
